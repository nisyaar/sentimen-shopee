# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gxbJdXdfoqgIlxxpJ7lyr9MczKfolCdH
"""

# Import semua library
import pandas as pd
import streamlit as st
import numpy as np
import re
import string
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from wordcloud import WordCloud
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

st.set_page_config(page_title="Analisis Sentimen Shopee", layout="wide")

# File .csv via google docs
data_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRKRoXEcfkA6ULR2Ijlsb4sNeOaBRzDEppuKiJSwVgIg4flNvqCbEZAjyNGBb0XTiFpVri6GYXwleCY/pub?gid=1792700066&single=true&output=csv'
data = pd.read_csv(data_url)
data

nltk.download('punkt')
nltk.download('stopwords')

def label_sentiment(score):
    if score <= 2:
        return "Negatif"
    elif score == 3:
        return "Netral"
    else:
        return "Positif"

data["sentiment"] = data["score"].apply(label_sentiment)

# Preprocessing teks
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"\d+", "", text)
    text = re.sub(r"[^\w\s]", "", text)
    text = text.translate(str.maketrans("", "", string.punctuation))
    return text.strip()

# Buat kolom clean_text
data['clean_text'] = data['content'].apply(clean_text)

# Split data
X = data['clean_text']
y = data['sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# 5. Buat model pipeline
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000)),
    ('clf', LogisticRegression(max_iter=1000))
])

pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)

# 6. Evaluasi
print("Akurasi:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# ========== Streamlit UI ==========
st.set_page_config(page_title="Analisis Sentimen Shopee", layout="wide")
st.title("ðŸ“Š Analisis Sentimen Ulasan Shopee")
st.markdown("Klasifikasi ulasan Shopee menjadi **Positif**, **Netral**, dan **Negatif** berdasarkan teks ulasan pengguna.")

user_input = st.text_input("Masukkan ulasan Shopee Anda:")
if user_input:
    clean_input = clean_text(user_input)
    prediction = pipeline.predict([clean_input])[0]
    st.success(f"Sentimen ulasan Anda: **{prediction.upper()}**")

# 7. Bar Chart Distribusi Sentimen
plt.figure(figsize=(6,4))
sns.countplot(data=data, x='sentiment', palette='pastel')
plt.title("Distribusi Sentimen")
plt.xlabel("Kategori Sentimen")
plt.ylabel("Jumlah Ulasan")
plt.tight_layout()
plt.show()

# 8. Word Cloud per Sentimen
for label in ['Positif', 'Netral', 'Negatif']:
    text = " ".join(data[data['sentiment'] == label]['clean_text'])
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)

    plt.figure(figsize=(10,5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title(f"Word Cloud - {label}", fontsize=16)
    plt.show()